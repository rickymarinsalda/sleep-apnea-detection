#!/usr/bin/env python3
"""
Complete Sleep Apnea Detection Analysis
Runs the full pipeline from data loading to cross-validation
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

from sklearn.ensemble import RandomForestClassifier
from sklearn.utils import resample
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.model_selection import GroupKFold
from sklearn.metrics import (
    roc_auc_score, roc_curve, auc,
    precision_score, recall_score, f1_score,
    confusion_matrix, precision_recall_curve
)

# Try to import XGBoost
try:
    import xgboost as xgb
    HAS_XGBOOST = True
except ImportError:
    HAS_XGBOOST = False
    print("Warning: XGBoost not available. Install with: pip install xgboost")

# Configuration
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)
TEST_SUBJECTS = ['GZ01', 'FDR01', 'AM01', 'FC01']
N_ESTIMATORS = 400
MIN_SAMPLES_LEAF = 3
K_FEATURES = 60

# Paths
BASE_DIR = Path(__file__).parent if "__file__" in dir() else Path(".")
RESULTS_DIR = BASE_DIR / "results_analysis"
RESULTS_DIR.mkdir(exist_ok=True)

# Dataset filename
DATASET_NAME = "dataset_apnea_windows_30s_features_zones_mat_acc_CORRECTED.csv"

# Search paths for dataset (in order of priority)
SEARCH_PATHS = [
    BASE_DIR / ".." / "data" / DATASET_NAME,           # ../data/ (GitHub structure)
    BASE_DIR / ".." / DATASET_NAME,                     # ../ (original structure)
    BASE_DIR / "preprocessing_output" / f"dataset_windows_30s_features_zones_CORRECTED.csv",  # preprocessing output
    Path(".") / DATASET_NAME,                           # current directory
]

def find_dataset():
    """Find the dataset file in multiple possible locations."""
    for path in SEARCH_PATHS:
        if path.exists():
            return path
    return None

print("=" * 80)
print(" " * 25 + "SLEEP APNEA DETECTION")
print(" " * 20 + "Complete Analysis Pipeline")
print("=" * 80)

# ============================================================================
# 1. LOAD DATASET
# ============================================================================
print("\n" + "=" * 80)
print("1. LOADING DATASET")
print("=" * 80)

DATASET_PATH = find_dataset()
if DATASET_PATH is None:
    print("\nERROR: Dataset not found!")
    print("Searched in:")
    for p in SEARCH_PATHS:
        print(f"  - {p}")
    print("\nPlease either:")
    print("  1. Run prepare_dataset.py first to generate the dataset")
    print("  2. Place the dataset file in one of the above locations")
    exit(1)

print(f"\nLoading: {DATASET_PATH}")
df = pd.read_csv(DATASET_PATH)

print(f"\nDataset shape: {df.shape}")
print(f"Total windows: {len(df)}")
print(f"Total subjects: {df['Subject'].nunique()}")
print(f"\nClass distribution:")
print(f"  Normal: {(df['label_apnea']==0).sum()} ({100*(df['label_apnea']==0).sum()/len(df):.1f}%)")
print(f"  Apnea:  {(df['label_apnea']==1).sum()} ({100*(df['label_apnea']==1).sum()/len(df):.1f}%)")

# ============================================================================
# 2. TRAIN/TEST SPLIT
# ============================================================================
print("\n" + "=" * 80)
print("2. TRAIN/TEST SPLIT (Subject-wise)")
print("=" * 80)

df_train = df[~df['Subject'].isin(TEST_SUBJECTS)].copy()
df_test = df[df['Subject'].isin(TEST_SUBJECTS)].copy()

print(f"\nTrain: {len(df_train)} windows, {df_train['Subject'].nunique()} subjects")
print(f"  Normal: {(df_train['label_apnea']==0).sum()}, Apnea: {(df_train['label_apnea']==1).sum()}")
print(f"\nTest: {len(df_test)} windows, {len(TEST_SUBJECTS)} subjects")
print(f"  Normal: {(df_test['label_apnea']==0).sum()}, Apnea: {(df_test['label_apnea']==1).sum()}")

# Select features (exclude metadata and target)
exclude_cols = ['Subject', 'label_apnea', 'start_time', 'end_time',
                'Position_mode', 'majority_status', 'frac_apnea',
                'frac_altro', 'frac_respiro']
baseline_features = [c for c in df_train.columns if c not in exclude_cols]

X_train = df_train[baseline_features]
y_train = df_train['label_apnea']
X_test = df_test[baseline_features]
y_test = df_test['label_apnea']

print(f"\nBaseline features: {len(baseline_features)}")

# ============================================================================
# 3. BASELINE MODEL
# ============================================================================
print("\n" + "=" * 80)
print("3. BASELINE MODEL (Simple Zones)")
print("=" * 80)

# Oversample minority class
X_train_maj = X_train[y_train == 0]
X_train_min = X_train[y_train == 1]
y_train_maj = y_train[y_train == 0]
y_train_min = y_train[y_train == 1]

X_train_min_up, y_train_min_up = resample(
    X_train_min, y_train_min,
    replace=True,
    n_samples=len(X_train_maj),
    random_state=RANDOM_STATE
)

X_train_bal = pd.concat([X_train_maj, X_train_min_up])
y_train_bal = pd.concat([y_train_maj, y_train_min_up])

print(f"\nOversampled: {len(y_train_bal)} samples (balanced)")

# Train baseline
print("\nTraining baseline Random Forest...")
rf_baseline = RandomForestClassifier(
    n_estimators=N_ESTIMATORS,
    min_samples_leaf=MIN_SAMPLES_LEAF,
    random_state=RANDOM_STATE,
    n_jobs=-1
)
rf_baseline.fit(X_train_bal, y_train_bal)

# Evaluate
y_pred_proba_base = rf_baseline.predict_proba(X_test)[:, 1]
y_pred_base = (y_pred_proba_base >= 0.5).astype(int)

roc_auc_base = roc_auc_score(y_test, y_pred_proba_base)
precision_base = precision_score(y_test, y_pred_base, zero_division=0)
recall_base = recall_score(y_test, y_pred_base, zero_division=0)
f1_base = f1_score(y_test, y_pred_base, zero_division=0)

print(f"\n‚úì Baseline Results:")
print(f"  ROC-AUC:   {roc_auc_base:.4f}")
print(f"  Precision: {precision_base:.4f}")
print(f"  Recall:    {recall_base:.4f}")
print(f"  F1-Score:  {f1_base:.4f}")

# ============================================================================
# 4. TEMPORAL FEATURES
# ============================================================================
print("\n" + "=" * 80)
print("4. TEMPORAL FEATURES (BREAKTHROUGH!)")
print("=" * 80)

def add_temporal_features(df):
    """Add temporal features to dataframe"""
    base_feats = [
        'global_mean', 'global_std', 'global_max',
        'zone_UL_mean_mean', 'zone_UR_mean_mean',
        'zone_LL_mean_mean', 'zone_LR_mean_mean',
        'zone_UL_diff_std_mean', 'zone_UR_diff_std_mean',
        'zone_LL_diff_std_mean', 'zone_LR_diff_std_mean',
        'acc_global_mean', 'acc_global_std',
    ]
    base_feats = [f for f in base_feats if f in df.columns]

    temporal_features = pd.DataFrame(index=df.index)

    for feat in base_feats:
        # Delta
        temporal_features[f'delta_{feat}'] = df.groupby('Subject')[feat].diff().fillna(0)
        # Rolling mean
        temporal_features[f'roll3_mean_{feat}'] = (
            df.groupby('Subject')[feat]
            .transform(lambda x: x.rolling(window=3, min_periods=1).mean())
        )
        # Rolling std
        temporal_features[f'roll3_std_{feat}'] = (
            df.groupby('Subject')[feat]
            .transform(lambda x: x.rolling(window=3, min_periods=1).std())
        ).fillna(0)
        # Trend
        temporal_features[f'trend_{feat}'] = (
            df[feat] - temporal_features[f'roll3_mean_{feat}']
        )

    return temporal_features

print("\nGenerating temporal features...")
temporal_train = add_temporal_features(df_train)
temporal_test = add_temporal_features(df_test)

X_train_temp = pd.concat([X_train.reset_index(drop=True),
                          temporal_train.reset_index(drop=True)], axis=1)
X_test_temp = pd.concat([X_test.reset_index(drop=True),
                         temporal_test.reset_index(drop=True)], axis=1)

print(f"Total features: {len(X_train_temp.columns)}")
print(f"  Original: {len(baseline_features)}")
print(f"  Temporal: {len(temporal_train.columns)}")

# Oversample with temporal features
# Use boolean indexing directly on the reset index
y_train_reset = y_train.reset_index(drop=True)
X_train_temp_maj = X_train_temp[y_train_reset == 0]
X_train_temp_min = X_train_temp[y_train_reset == 1]

X_train_temp_min_up, y_train_temp_min_up = resample(
    X_train_temp_min, y_train_min,
    replace=True,
    n_samples=len(X_train_temp_maj),
    random_state=RANDOM_STATE
)

X_train_temp_bal = pd.concat([X_train_temp_maj, X_train_temp_min_up])
y_train_temp_bal = pd.concat([y_train_maj, y_train_temp_min_up])

# Feature selection
print(f"\nSelecting top K={K_FEATURES} features...")
selector = SelectKBest(f_classif, k=K_FEATURES)
X_train_selected = selector.fit_transform(X_train_temp_bal, y_train_temp_bal)
X_test_selected = selector.transform(X_test_temp)

selected_features = X_train_temp.columns[selector.get_support()].tolist()

# Train RF with temporal features
print("\nTraining Random Forest with temporal features...")
rf_temporal = RandomForestClassifier(
    n_estimators=N_ESTIMATORS,
    min_samples_leaf=MIN_SAMPLES_LEAF,
    random_state=RANDOM_STATE,
    n_jobs=-1
)
rf_temporal.fit(X_train_selected, y_train_temp_bal)

# Evaluate
y_pred_proba_temp = rf_temporal.predict_proba(X_test_selected)[:, 1]
y_pred_temp = (y_pred_proba_temp >= 0.30).astype(int)

roc_auc_temp = roc_auc_score(y_test, y_pred_proba_temp)
precision_temp = precision_score(y_test, y_pred_temp, zero_division=0)
recall_temp = recall_score(y_test, y_pred_temp, zero_division=0)
f1_temp = f1_score(y_test, y_pred_temp, zero_division=0)

print(f"\n‚úì RF + Temporal Results (threshold=0.30):")
print(f"  ROC-AUC:   {roc_auc_temp:.4f}")
print(f"  Precision: {precision_temp:.4f}")
print(f"  Recall:    {recall_temp:.4f}")
print(f"  F1-Score:  {f1_temp:.4f}")

print(f"\nüéâ IMPROVEMENT over baseline:")
print(f"  ROC-AUC: {roc_auc_base:.4f} ‚Üí {roc_auc_temp:.4f} (+{100*(roc_auc_temp/roc_auc_base-1):.1f}%)")
print(f"  F1-Score: {f1_base:.4f} ‚Üí {f1_temp:.4f} (+{100*(f1_temp/f1_base-1):.1f}%)")

# Feature importance
feature_importance = pd.DataFrame({
    'feature': selected_features,
    'importance': rf_temporal.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\nTop 10 Most Important Features:")
for i, row in feature_importance.head(10).iterrows():
    is_temporal = any(x in row['feature'] for x in ['delta_', 'roll3_', 'trend_'])
    feat_type = "Temporal" if is_temporal else "Original"
    print(f"  {i+1:2d}. {row['feature']:45s} {row['importance']*100:5.2f}% [{feat_type}]")

temporal_count = sum(any(x in feat for x in ['delta_', 'roll3_', 'trend_'])
                     for feat in feature_importance.head(10)['feature'])
print(f"\n‚úì {temporal_count}/10 top features are temporal!")

# ============================================================================
# 4B. XGBOOST (OPTIONAL)
# ============================================================================
if HAS_XGBOOST:
    print("\n" + "=" * 80)
    print("4B. XGBOOST + TEMPORAL (COMPARISON)")
    print("=" * 80)

    print("\nTraining XGBoost with temporal features...")
    xgb_model = xgb.XGBClassifier(
        n_estimators=N_ESTIMATORS,
        max_depth=6,
        learning_rate=0.1,
        random_state=RANDOM_STATE,
        n_jobs=-1,
        eval_metric='logloss'
    )
    xgb_model.fit(X_train_selected, y_train_temp_bal)

    # Evaluate
    y_pred_proba_xgb = xgb_model.predict_proba(X_test_selected)[:, 1]
    y_pred_xgb = (y_pred_proba_xgb >= 0.30).astype(int)

    roc_auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)
    precision_xgb = precision_score(y_test, y_pred_xgb, zero_division=0)
    recall_xgb = recall_score(y_test, y_pred_xgb, zero_division=0)
    f1_xgb = f1_score(y_test, y_pred_xgb, zero_division=0)

    print(f"\n‚úì XGBoost Results (threshold=0.30):")
    print(f"  ROC-AUC:   {roc_auc_xgb:.4f}")
    print(f"  Precision: {precision_xgb:.4f}")
    print(f"  Recall:    {recall_xgb:.4f}")
    print(f"  F1-Score:  {f1_xgb:.4f}")

    print(f"\nüìä RF vs XGBoost:")
    print(f"  ROC-AUC: RF {roc_auc_temp:.4f} vs XGB {roc_auc_xgb:.4f} (Œî{roc_auc_xgb-roc_auc_temp:+.4f})")
    print(f"  F1-Score: RF {f1_temp:.4f} vs XGB {f1_xgb:.4f} (Œî{f1_xgb-f1_temp:+.4f})")
else:
    print("\n‚ö†Ô∏è  XGBoost not available - skipping comparison")
    y_pred_proba_xgb = None
    y_pred_xgb = None
    roc_auc_xgb = None
    precision_xgb = None
    recall_xgb = None
    f1_xgb = None

# ============================================================================
# 5. CROSS-VALIDATION
# ============================================================================
print("\n" + "=" * 80)
print("5. CROSS-VALIDATION (5-fold GroupKFold)")
print("=" * 80)

print("\nRunning 5-fold cross-validation (this may take a few minutes)...")

# Prepare full dataset
X_full = df[baseline_features]
y_full = df['label_apnea']
subjects_full = df['Subject']

# Generate temporal for full dataset
temporal_full = add_temporal_features(df)
X_full_temp = pd.concat([X_full.reset_index(drop=True),
                         temporal_full.reset_index(drop=True)], axis=1)

# CV
gkf = GroupKFold(n_splits=5)
cv_results = {'Baseline': [], 'RF+Temporal': []}
if HAS_XGBOOST:
    cv_results['XGBoost+Temporal'] = []

for fold, (train_idx, test_idx) in enumerate(gkf.split(X_full, y_full, groups=subjects_full), 1):
    print(f"  Fold {fold}/5...", end=" ")

    # Split
    X_tr, X_te = X_full.iloc[train_idx], X_full.iloc[test_idx]
    X_tr_temp, X_te_temp = X_full_temp.iloc[train_idx], X_full_temp.iloc[test_idx]
    y_tr, y_te = y_full.iloc[train_idx], y_full.iloc[test_idx]

    # Oversample baseline
    X_tr_maj = X_tr[y_tr == 0]
    X_tr_min = X_tr[y_tr == 1]
    y_tr_maj = y_tr[y_tr == 0]
    y_tr_min = y_tr[y_tr == 1]

    X_tr_min_up, y_tr_min_up = resample(
        X_tr_min, y_tr_min,
        replace=True, n_samples=len(X_tr_maj),
        random_state=RANDOM_STATE
    )

    X_tr_bal = pd.concat([X_tr_maj, X_tr_min_up])
    y_tr_bal = pd.concat([y_tr_maj, y_tr_min_up])

    # Baseline
    rf_base_cv = RandomForestClassifier(
        n_estimators=N_ESTIMATORS,
        min_samples_leaf=MIN_SAMPLES_LEAF,
        random_state=RANDOM_STATE,
        n_jobs=-1
    )
    rf_base_cv.fit(X_tr_bal, y_tr_bal)
    y_pred_base_cv = rf_base_cv.predict_proba(X_te)[:, 1]
    cv_results['Baseline'].append(roc_auc_score(y_te, y_pred_base_cv))

    # RF + Temporal
    # Oversample temporal
    X_tr_temp_maj = X_tr_temp.iloc[(y_tr == 0).values]
    X_tr_temp_min = X_tr_temp.iloc[(y_tr == 1).values]

    X_tr_temp_min_up, _ = resample(
        X_tr_temp_min, y_tr_min,
        replace=True, n_samples=len(X_tr_temp_maj),
        random_state=RANDOM_STATE
    )

    X_tr_temp_bal = pd.concat([X_tr_temp_maj, X_tr_temp_min_up])
    y_tr_temp_bal = pd.concat([y_tr_maj, y_tr_min_up])

    # Feature selection
    sel_cv = SelectKBest(f_classif, k=K_FEATURES)
    X_tr_sel = sel_cv.fit_transform(X_tr_temp_bal, y_tr_temp_bal)
    X_te_sel = sel_cv.transform(X_te_temp)

    rf_temp_cv = RandomForestClassifier(
        n_estimators=N_ESTIMATORS,
        min_samples_leaf=MIN_SAMPLES_LEAF,
        random_state=RANDOM_STATE,
        n_jobs=-1
    )
    rf_temp_cv.fit(X_tr_sel, y_tr_temp_bal)
    y_pred_temp_cv = rf_temp_cv.predict_proba(X_te_sel)[:, 1]
    cv_results['RF+Temporal'].append(roc_auc_score(y_te, y_pred_temp_cv))

    # XGBoost CV
    if HAS_XGBOOST:
        xgb_cv = xgb.XGBClassifier(
            n_estimators=N_ESTIMATORS,
            max_depth=6,
            learning_rate=0.1,
            random_state=RANDOM_STATE,
            n_jobs=-1,
            eval_metric='logloss'
        )
        xgb_cv.fit(X_tr_sel, y_tr_temp_bal)
        y_pred_xgb_cv = xgb_cv.predict_proba(X_te_sel)[:, 1]
        cv_results['XGBoost+Temporal'].append(roc_auc_score(y_te, y_pred_xgb_cv))
        print(f"Baseline: {cv_results['Baseline'][-1]:.3f}, RF+Temp: {cv_results['RF+Temporal'][-1]:.3f}, XGB+Temp: {cv_results['XGBoost+Temporal'][-1]:.3f}")
    else:
        print(f"Baseline: {cv_results['Baseline'][-1]:.3f}, RF+Temp: {cv_results['RF+Temporal'][-1]:.3f}")

print(f"\n‚úì Cross-validation completed")

print(f"\nCV Results Summary:")
for model, results in cv_results.items():
    mean_auc = np.mean(results)
    std_auc = np.std(results)
    print(f"  {model:12s}: {mean_auc:.4f} ¬± {std_auc:.4f} (range: [{min(results):.2f}, {max(results):.2f}])")

rf_cv_mean = np.mean(cv_results['RF+Temporal'])
baseline_cv_mean = np.mean(cv_results['Baseline'])
improvement = 100 * (rf_cv_mean - baseline_cv_mean) / baseline_cv_mean

print(f"\n‚úì Robust improvement: +{improvement:.1f}% ({baseline_cv_mean:.3f} ‚Üí {rf_cv_mean:.3f})")

# ============================================================================
# 6. VISUALIZATIONS
# ============================================================================
print("\n" + "=" * 80)
print("6. GENERATING VISUALIZATIONS")
print("=" * 80)

# ROC Curves
fig, ax = plt.subplots(figsize=(10, 8))

fpr_base, tpr_base, _ = roc_curve(y_test, y_pred_proba_base)
fpr_temp, tpr_temp, _ = roc_curve(y_test, y_pred_proba_temp)

ax.plot(fpr_base, tpr_base, color='#FF6B6B', linewidth=2.5,
        label=f'Baseline (AUC={roc_auc_base:.4f})')
ax.plot(fpr_temp, tpr_temp, color='#4ECDC4', linewidth=2.5,
        label=f'RF + Temporal (AUC={roc_auc_temp:.4f})')

# Add XGBoost if available
if HAS_XGBOOST and y_pred_proba_xgb is not None:
    fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_proba_xgb)
    ax.plot(fpr_xgb, tpr_xgb, color='#FFA500', linewidth=2.5,
            label=f'XGBoost + Temporal (AUC={roc_auc_xgb:.4f})')

ax.plot([0, 1], [0, 1], 'k--', linewidth=1.5, alpha=0.5, label='Random (AUC=0.5000)')

ax.set_xlabel('False Positive Rate', fontsize=12)
ax.set_ylabel('True Positive Rate', fontsize=12)
ax.set_title('ROC Curves Comparison (CORRECTED zones)', fontsize=14, fontweight='bold')
ax.legend(loc='lower right', fontsize=10)
ax.grid(alpha=0.3)

plt.tight_layout()
plt.savefig(RESULTS_DIR / 'roc_curves_CORRECTED.png', dpi=150, bbox_inches='tight')
print(f"‚úì Saved: roc_curves_CORRECTED.png")
plt.close()

# Confusion Matrices
n_models = 3 if (HAS_XGBOOST and y_pred_xgb is not None) else 2
fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 5))
if n_models == 2:
    axes = [axes[0], axes[1]]

cm_base = confusion_matrix(y_test, y_pred_base)
cm_temp = confusion_matrix(y_test, y_pred_temp)

models_data = [
    (cm_base, 'Baseline', (roc_auc_base, precision_base, recall_base, f1_base)),
    (cm_temp, 'RF + Temporal (thr=0.30)', (roc_auc_temp, precision_temp, recall_temp, f1_temp))
]

if HAS_XGBOOST and y_pred_xgb is not None:
    cm_xgb = confusion_matrix(y_test, y_pred_xgb)
    models_data.append((cm_xgb, 'XGBoost + Temporal (thr=0.30)', (roc_auc_xgb, precision_xgb, recall_xgb, f1_xgb)))

for idx, (cm, title, results) in enumerate(models_data):
    ax = axes[idx]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax,
                xticklabels=['Negative', 'Positive'],
                yticklabels=['Negative', 'Positive'])
    ax.set_title(title, fontsize=12, fontweight='bold')
    ax.set_xlabel('Predicted', fontsize=11)
    ax.set_ylabel('Actual', fontsize=11)

    auc_val, prec, rec, f1_val = results
    ax.text(0.5, -0.15,
            f"ROC-AUC: {auc_val:.3f} | Prec: {prec:.3f} | Rec: {rec:.3f} | F1: {f1_val:.3f}",
            transform=ax.transAxes, ha='center', fontsize=9)

plt.tight_layout()
plt.savefig(RESULTS_DIR / 'confusion_matrices_CORRECTED.png', dpi=150, bbox_inches='tight')
print(f"‚úì Saved: confusion_matrices_CORRECTED.png")
plt.close()

# ============================================================================
# FINAL SUMMARY
# ============================================================================
print("\n" + "=" * 80)
print(" " * 28 + "FINAL SUMMARY")
print("=" * 80)

print(f"\nüìä Single Train/Test Split Performance:")
print(f"  {'Model':<30} {'ROC-AUC':>10} {'F1-Score':>10} {'Precision':>10} {'Recall':>10}")
print(f"  {'-'*77}")
print(f"  {'Baseline':<30} {roc_auc_base:>10.4f} {f1_base:>10.4f} {precision_base:>10.4f} {recall_base:>10.4f}")
print(f"  {'RF + Temporal (K=60)':<30} {roc_auc_temp:>10.4f} {f1_temp:>10.4f} {precision_temp:>10.4f} {recall_temp:>10.4f}")
if HAS_XGBOOST and roc_auc_xgb is not None:
    print(f"  {'XGBoost + Temporal (K=60)':<30} {roc_auc_xgb:>10.4f} {f1_xgb:>10.4f} {precision_xgb:>10.4f} {recall_xgb:>10.4f}")

print(f"\nüìä 5-Fold Cross-Validation Performance:")
print(f"  {'Model':<25} {'ROC-AUC (mean¬±std)':>25}")
print(f"  {'-'*52}")
for model, results in cv_results.items():
    mean_val, std_val = np.mean(results), np.std(results)
    print(f"  {model:<25} {mean_val:>10.4f} ¬± {std_val:<6.4f}")

print(f"\n" + "=" * 80)
print("KEY FINDINGS:")
print("=" * 80)

print(f"\n1Ô∏è‚É£ Temporal features provide DRAMATIC improvement")
print(f"   Single-split: +{100*(roc_auc_temp/roc_auc_base-1):.1f}% ROC-AUC")
print(f"   Cross-val: +{improvement:.1f}% ROC-AUC")

print(f"\n2Ô∏è‚É£ Single-split was optimistic")
print(f"   Single: {roc_auc_temp:.4f}, CV mean: {rf_cv_mean:.4f}")
print(f"   But still GOOD (>0.80 threshold)")

print(f"\n3Ô∏è‚É£ {temporal_count}/10 top features are temporal")

print(f"\n4Ô∏è‚É£ Subject-dependent performance")
print(f"   CV range: [{min(cv_results['RF+Temporal']):.2f}, {max(cv_results['RF+Temporal']):.2f}]")

print(f"\n" + "=" * 80)
print(f"\n‚úÖ Analysis completed successfully!")
print(f"\nüìÅ Results saved to: {RESULTS_DIR}/")
print(f"\nGenerated files:")
for f in sorted(RESULTS_DIR.glob('*.png')):
    print(f"  - {f.name}")

print("\n" + "=" * 80)
